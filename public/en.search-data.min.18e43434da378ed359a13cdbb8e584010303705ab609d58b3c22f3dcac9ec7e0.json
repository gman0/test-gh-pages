[{"id":0,"href":"/docs/00-prerequisites/","title":"00: Setting up your development environment","section":"Docs","content":" Pre-requisites # In this chapter we\u0026rsquo;ll set up our workshop-dedicated development environment.\nCloning the workshop repo # Start by cloning the git repository we\u0026rsquo;ll refer to throughout the workshop, and will be the place for the binaries, scripts and kubeconfigs we will create as we move forward.\ngit clone git@github.com:mjudeikis/kcp-contrib.git Now, let\u0026rsquo;s see what\u0026rsquo;s inside.\n00-prerequisites/ 01-deploy-kcp/ 02-explore-workspaces/ 03-dynamic-providers/ clean-all.sh Notice the exercises in directories \u0026lt;Sequence number\u0026gt;-\u0026lt;Exercise name\u0026gt;. These are to be visited in sequence, and to complete one, all previous exercises need to be completed first to bring the system into the desired state. While it\u0026rsquo;s best if you try to follow the tasks by yourself, if you ever get stuck, you can finish an exercise by running the scripts inside the respective exercise directory.\nAlso take a note of the clean-all.sh script. If you ever get stuck and want to reset, run it and it will clean up and stop processes and containers used in the exercises.\nGet your bins # This one is easy. During the workshop we will make use of these programs:\nkcp, kcp\u0026rsquo;s api-syncagent, kind, kubectl, and, kubectl-krew. You may visit the links, download and extract the respective binaries to a new directory called bin/ in the workshop\u0026rsquo;s root (e.g., $WORKSHOP/bin/kubectl). If you already have some of these installed and available in your $PATH, you may skip them\u0026ndash;just make sure they are up-to-date.\nAlternatively, we\u0026rsquo;ve prepared a script that does just that:\n00-prerequisites/01-install.sh If you\u0026rsquo;re going the manual way, please make sure the file names are stripped of OS and arch names they may contain (e.g. mv kubectl-krew-linux_amd64 kubectl-krew), as we\u0026rsquo;ll refer to them using their system-agnostic names later on.\nAnd that\u0026rsquo;s it!\nðŸš€ðŸš€ðŸš€\nHigh-five! # Done already? High-five! Check-in your completion with:\n00-prerequisites/99-highfive.sh If there were no errors, you may continue with the next exercise: Deploying kcp.\n"},{"id":1,"href":"/docs/01-deploy-kcp/","title":"01: Deploying kcp","section":"Docs","content":" Deploy kcp # kcp may be deployed via a Helm chart, an operator, or as a standalone process running on the host. Each of them has its uses as well as advantages and disadvantages. While the most preferable way to deploy kcp is using its dedicated operator, for the sake of simplicity, we\u0026rsquo;ve taken the liberty of making the choice for you :) .\nStarting kcp as a standalone process # Attention: during these exercises, we\u0026rsquo;ll be making heavy use of environment variables. We will be switching back and forth between clusters, as well as needing access to the binaries we\u0026rsquo;ve set up in the previous chapter. Whenever you see this block, it means we are switching an environment. Make sure you cd into the workshop git repo, and copy-paste the commands to your terminal. Let\u0026rsquo;s give it a try!\nBash/ZSH export WORKSHOP_ROOT=\u0026#34;$(git rev-parse --show-toplevel)/20250401-kubecon-london/workshop-\u0026#34; export PATH=\u0026#34;${WORKSHOP_ROOT}/bin:${PATH}\u0026#34; Fish set WORKSHOP_ROOT (git rev-parse --show-toplevel)/20250401-kubecon-london/workshop- set PATH $WORKSHOP_ROOT/bin $PATH Starting kcp in standalone mode is as easy as typing kcp start and pressing Enter:\nkcp start You should see the program running indefinitely, and outputting its logs\u0026ndash;starting with some errors that should clean up in a couple of seconds as the different controllers start up. Leave the terminal window open, as we will keep using this kcp instance throughout the duration of the workshop. In this mode, all kcp\u0026rsquo;s state is in-memory only. That means exiting the process (by, for example, pressing Ctrl+C in this terminal), will lose all its etcd contents.\nOnce kcp\u0026rsquo;s output seems stable, we can start making simple kubectl calls against it. kcp start creates a hidden directory .kcp, where it places its kubeconfig and the certificates.\nOpen a new terminal now.\nBash/ZSH export WORKSHOP_ROOT=\u0026#34;$(git rev-parse --show-toplevel)/20250401-kubecon-london/workshop-\u0026#34; export KUBECONFIG=\u0026#34;${workshop_root}/.kcp/admin.kubeconfig\u0026#34; Fish set WORKSHOP_ROOT (git rev-parse --show-toplevel)/20250401-kubecon-london/workshop- set KUBECONFIG $WORKSHOP_ROOT/.kcp/admin.kubeconfig\u0026#34; The following command should work now:\n$ kubectl version Client Version: v1.32.1 Kustomize Version: v5.5.0 Server Version: v1.31.0+kcp-v0.26.1 We\u0026rsquo;ll have a couple more kubeconfigs to switch between, and it will be convenient to have them all in one place. Let\u0026rsquo;s do that now:\nmkdir $WORKSHOP_ROOT/kubeconfigs ln -s $KUBECONFIG $WORKSHOP_ROOT/kubeconfigs And that\u0026rsquo;s it!\nðŸš€ðŸš€ðŸš€\nHigh-five! # Finished? High-five! Check-in your completion with:\n01-deploy-kcp/99-highfive.sh If there were no errors, you may continue with the next exercise: Explore workspaces.\nCheat-sheet # You may fast-forward through this exercise by running:\n01-deploy-kcp/01-start-kcp.sh in a new terminal "},{"id":2,"href":"/docs/02-explore-workspaces/","title":"02: Exploring workspaces","section":"Docs","content":" Explore workspaces # Workspaces are one of kcp\u0026rsquo;s core concepts, and in this exercise we\u0026rsquo;ll explore what they are and how to work with them.\nSee Workspaces documentation at docs.kcp.io/kcp/main/concepts/workspaces/.\nPre-requisites, take two # Workspaces, or kcp for that matter, is not something that vanilla kubectl knows about. kcp brings support for those using krew plugins. You may remember, we installed kubect-krew in the very first warm-up exercise. Now we need to install the plugins themselves:\nBash/ZSH export WORKSHOP_ROOT=\u0026#34;$(git rev-parse --show-toplevel)/20250401-kubecon-london/workshop-\u0026#34; export KREW_ROOT=\u0026#34;${workshop_root}/bin/.krew\u0026#34; export PATH=\u0026#34;${WORKSHOP_ROOT}/bin/.krew/bin:${WORKSHOP_ROOT}/bin:${PATH}\u0026#34; Fish set -gx WORKSHOP_ROOT (git rev-parse --show-toplevel)/20250401-kubecon-london/workshop- set -gx KREW_ROOT $WORKSHOP_ROOT/bin/.krew set -gx PATH $WORKSHOP_ROOT/bin/.krew/bin $WORKSHOP_ROOT/bin $PATH\u0026#34; kubectl krew index add kcp-dev https://github.com/kcp-dev/krew-index.git kubectl krew install kcp-dev/kcp kubectl krew install kcp-dev/ws kubectl krew install kcp-dev/create-workspace Now you should be able to run and inspect these commands:\n$ kubectl create workspace --help Creates a new workspace Usage: create [flags] ... $ kubectl ws --help Manages KCP workspaces Usage: workspace [create|create-context|use|current|\u0026lt;workspace\u0026gt;|..|.|-|~|\u0026lt;root:absolute:workspace\u0026gt;] [flags] workspace [command] ... $ kubectl kcp --help ... With that, let\u0026rsquo;s create some workspaces!\nSprawling workspaces # Bash/ZSH export WORKSHOP_ROOT=\u0026#34;$(git rev-parse --show-toplevel)/20250401-kubecon-london/workshop-\u0026#34; export KREW_ROOT=\u0026#34;${WORKSHOP_ROOT}/bin/.krew\u0026#34; export PATH=\u0026#34;${workshop_root}/bin/.krew/bin:${workshop_root}/bin:${PATH}\u0026#34; Fish set -gx WORKSHOP_ROOT (git rev-parse --show-toplevel)/20250401-kubecon-london/workshop- set -gx KREW_ROOT $WORKSHOP_ROOT/bin/.krew set -gx PATH $WORKSHOP_ROOT/bin/.krew/bin $WORKSHOP_ROOT/bin $PATH\u0026#34; We\u0026rsquo;ll be using kubectl create workspace command:\nkubectl create workspace one kubectl create workspace two kubectl create workspace three --enter kubectl create workspace potato Now, let\u0026rsquo;s list what we\u0026rsquo;ve created:\nkubectl ws use : kubectl get ws These are the workspaces we created, and they represent logical separation of resources in the cluster.\nWe haven\u0026rsquo;t seen ws use yet. Using this command, you move into a different workspace in the tree of workspaces, much like cd moves you into a different directory described by a path. In case of workspaces, a path too may be relative or absolute, where : is the path separator, and : alone denotes the root of the tree.\nkubectl ws use : kubectl ws use one kubectl get configmap kubectl create configmap test --from-literal=test=one kubectl get configmap test -o json kubectl ws use root:two kubectl get configmap kubectl create configmap test --from-literal=test=two kubectl get configmap test -o json Notice how even though these two ConfigMaps have the same name test, and are in the same namespace default, they are actually two distinct objects. They live in two different workspaces, and are completely separate.\nWe\u0026rsquo;ve created a few workspaces now, and already it\u0026rsquo;s easy to lose sight of what is where. Say hello to ws tree:\nkubectl ws use : kubectl ws tree You should get output similar to this:\n. â””â”€â”€ root â”œâ”€â”€ one â”œâ”€â”€ three â”‚ â””â”€â”€ potato â””â”€â”€ two Exporting and binding APIs across workspaces # Isolation is nice, but what if you need to share?\nSee docs.kcp.io/kcp/main/concepts/apis/exporting-apis/ for detailed documentation.\nAs you\u0026rsquo;ll see next, sharing in this context will be a very well-defined and constrained relationship of provisioning and consuming. We shall model that relationship using workspaces.\nService provider # Create providers and providers:cowboys workspaces:\nkubectl ws use : kubectl ws create providers --enter kubectl ws create cowboys --enter $ kubectl ws use : Current workspace is \u0026#39;root\u0026#39;. $ kubectl ws tree . â””â”€â”€ root â”œâ”€â”€ one â”œâ”€â”€ providers â”‚ â””â”€â”€ cowboys â”œâ”€â”€ three â”‚ â””â”€â”€ potato â””â”€â”€ two $ kubectl ws use :root:providers:cowboys Current workspace is \u0026#39;root:providers:cowboys\u0026#39; (type root:universal). Now that we\u0026rsquo;re in :root:providers:cowboys, let\u0026rsquo;s create an APIResourceSchema and an APIExport. We\u0026rsquo;ll discuss what are they for next.\nkubectl create -f $WORKSHOP_ROOT/02-explore-workspaces/apis/apiresourceschema.yaml kubectl create -f $WORKSHOP_ROOT/02-explore-workspaces/apis/apiexport.yaml Starting with the first one, APIResourceSchema:\nkubectl get apiresourceschema -o json Try to skim through the YAML output and you\u0026rsquo;ll notice that it is almost identical to a definition of a CRD. Unlinke a CRD however, APIResourceSchema instance does not have a backing API server, and instead it simply describes an API that we can pass around and refer to. By decoupling the schema definition from serving, API owners can be more explicit about API evolution.\nkubectl get apiexport cowboys -o yaml Take a note of the following properties in the output:\n.spec.latestResourceSchemas: refers to specific versions of APIResourceSchema objects, .spec.permissionClaims: describes resource permissions that our API depends on. These are the permissions that we, the service provider, want the consumer to grant us, .status.virtualWorkspaces[].url: the URL where the provider can access the granted resources. # Stripped down example output of `kubectl get apiexport` command above. spec: latestResourceSchemas: - today.cowboys.wildwest.dev permissionClaims: - all: true group: \u0026#34;\u0026#34; resource: configmaps status: virtualWorkspaces: - url: https://192.168.32.7:6443/services/apiexport/1ctnpog1ny8bnud6/cowboys Service consumer # With the provider in place, let\u0026rsquo;s create two consumers their own workspaces, starting with \u0026ldquo;wild-west\u0026rdquo;:\nkubectl ws use : kubectl create workspace consumers --enter kubectl create workspace wild-west --enter kubectl kcp bind apiexport root:providers:cowboys:cowboys --name cowboys-consumer kubectl create -f $WORKSHOP_ROOT/02-explore-workspaces/apis/consumer-wild-west.yaml Let\u0026rsquo;s check the Cowboy we have created:\n$ kubectl get cowboy buckaroo-bill -o json { \u0026#34;apiVersion\u0026#34;: \u0026#34;wildwest.dev/v1alpha1\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;Cowboy\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;annotations\u0026#34;: { \u0026#34;kcp.io/cluster\u0026#34;: \u0026#34;2snrfbp1a3gww1hu\u0026#34; }, \u0026#34;creationTimestamp\u0026#34;: \u0026#34;2025-03-12T09:06:53Z\u0026#34;, \u0026#34;generation\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;buckaroo-bill\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;3164\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;bb6ece46-84bc-4673-a926-f38c486799cf\u0026#34; }, \u0026#34;spec\u0026#34;: { \u0026#34;intent\u0026#34;: \u0026#34;Ride and protect the wild west!!!\u0026#34; } } And the second consumer, \u0026ldquo;wild-north\u0026rdquo;:\nkubectl ws use .. kubectl create workspace wild-north --enter kubectl kcp bind apiexport root:providers:cowboys:cowboys --name cowboys-consumer kubectl create -f $WORKSHOP_ROOT/02-explore-workspaces/apis/consumer-wild-north.yaml $ kubectl get cowboy hold-the-wall -o json { \u0026#34;apiVersion\u0026#34;: \u0026#34;wildwest.dev/v1alpha1\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;Cowboy\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;annotations\u0026#34;: { \u0026#34;kcp.io/cluster\u0026#34;: \u0026#34;30j93qa92345q3tp\u0026#34; }, \u0026#34;creationTimestamp\u0026#34;: \u0026#34;2025-03-12T09:09:32Z\u0026#34;, \u0026#34;generation\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;hold-the-wall\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;3227\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;ff96ab88-b738-4af7-8cc0-3872c424d9df\u0026#34; }, \u0026#34;spec\u0026#34;: { \u0026#34;intent\u0026#34;: \u0026#34;North is there the wall is!\u0026#34; } } Great! We have created two instances of a common API, and were able to create a couple of dummy objects with it.\n$ kubectl ws use : Current workspace is \u0026#39;root\u0026#39;. $ kubectl ws tree . â””â”€â”€ root â”œâ”€â”€ consumers â”‚ â”œâ”€â”€ wild-north â”‚ â””â”€â”€ wild-west â”œâ”€â”€ one â”œâ”€â”€ providers â”‚ â””â”€â”€ cowboys â”œâ”€â”€ three â”‚ â””â”€â”€ potato â””â”€â”€ two Spec up, status down # We have been moving across namespaces up and down, changing our implied roles. Let\u0026rsquo;s become the service provider again, and see what we can make out from our cowboys APIExport.\nkubectl ws :root:providers:cowboys kubectl get apiexport cowboys -o json | jq \u0026#39;.status.virtualWorkspaces[].url\u0026#39; Using that URL, we can confirm that only the resources we have agreed on are available to the workspaces.\n$ kubectl -s \u0026#39;https://192.168.32.7:6443/services/apiexport/1ctnpog1ny8bnud6/cowboys/clusters/*\u0026#39; api-resources NAME SHORTNAMES APIVERSION NAMESPACED KIND configmaps v1 true ConfigMap apibindings apis.kcp.io/v1alpha1 false APIBinding cowboys wildwest.dev/v1alpha1 true Cowboy We can also list all consumers (i.e. workspaces that have relevant APIBinding) for cowboys APIExport:\n$ kubectl -s \u0026#39;https://192.168.32.7:6443/services/apiexport/1ctnpog1ny8bnud6/cowboys/clusters/*\u0026#39; get cowboys -A NAMESPACE NAME default buckaroo-bill default hold-the-wall You can play around with inspecting the json output of those commands, and try addressing a specific cluster instead of all of them (wildcard *) to get some intuition about how they are wired together.\nFrom that, we can start imagining what a workspace-aware controller operating on these objects would look like; it would have a global view of consumers and would be able to reconcile globally too. Excited? Let\u0026rsquo;s continue with the next exercise: Link.\nðŸš€ðŸš€ðŸš€\nHigh-five! # Finished? High-five! Check-in your completion with:\n../02-explore-workspaces/99-highfive.sh Cheat-sheet # You may fast-forward through this exercise by running:\n02-explore-workspaces/00-install-krew-plugins.sh 02-explore-workspaces/01-create-apis.sh 02-explore-workspaces/02-create-consumers.sh 02-explore-workspaces/99-highfive.sh "}]